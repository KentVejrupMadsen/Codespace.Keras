{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kentvejrupmadsen/classification-of-letters?scriptVersionId=133635583\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"%pip install ipykernel\n!python -m ipykernel install --user --name=notebook_environment\n\n%pip install matplotlib\n%pip install keras\n%pip install tensorflow\n%pip install kaggle\n%pip install numpy\n%pip install wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-14T13:10:46.037241Z","iopub.execute_input":"2023-06-14T13:10:46.037796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random \\\n    import SystemRandom\n\nimport tensorflow\n\nfrom tensorflow.data \\\n    import AUTOTUNE\n\nfrom kaggle_secrets \\\n    import UserSecretsClient\n\nfrom keras.losses \\\n    import SparseCategoricalCrossentropy\n\nfrom keras.utils \\\n    import image_dataset_from_directory\n\nfrom keras \\\n    import \\\n    Model, \\\n    Sequential\n\nfrom keras \\\n    import layers\n\nimport wandb\n\nfrom wandb.integration.keras \\\n    import \\\n    WandbCallback, \\\n    WandbEvalCallback, \\\n    WandbMetricsLogger, \\\n    WandbModelCheckpoint","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"secrets = UserSecretsClient()\nrandom_generator = SystemRandom()\n\n# Constants\ndef label_training() -> str:\n    return 'training'\n\ndef label_validation() -> str:\n    return 'validation'\n\ndef empty_string() -> str:\n    return ''\n\ndef zero() -> int:\n    return 0\n\ndef get_log_runs() -> bool:\n    global log_runs\n    return log_runs\n\ndef get_gpus_to_use() -> list:\n    return [ '/gpu:0', '/gpu:1' ]\n\n# Dynamic\ndef set_size_of_training_set_categories(\n    value: int\n) -> None:\n    global configuration\n    configuration['dataset']['training']['size'] = value\n\ndef set_labels_of_training_set(\n    value: list\n) -> None:\n    global configuration\n    configuration['dataset']['training']['labels'] = value\n    set_size_of_training_set_categories(\n        len(\n            value\n        )\n    )\n\ndef get_size_of_training_set_categories() -> int:\n    global configuration\n    return configuration['dataset']['training']['size']\n\ndef set_size_of_validation_set_categories(\n    value: int\n) -> None:\n    global configuration\n    configuration['dataset']['validation']['size'] = value\n\ndef set_labels_of_validation_set(\n    value: list\n) -> None:\n    global configuration\n    configuration['dataset']['validation']['labels'] = value\n    \n    set_size_of_validation_set_categories(\n        len(\n            value\n        )\n    )\n\ndef get_size_of_validation_set_categories() -> int:\n    global configuration\n    return configuration['dataset']['validation']['size']\n\ndef get_max_random_value() -> int:\n    return 16777215\n\ndef get_min_random_value() -> int:\n    return zero()\n\ndef generate_random_seed() -> int:\n    global random_generator\n    \n    return random_generator.randint(\n        get_min_random_value(), \n        get_max_random_value()\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"__wandb_key: str = secrets.get_secret(\n    '__wandb__'\n)\n\n    \ndef get_wandb_secret() -> str:\n    global __wandb_key\n    \n    if __wandb_key is None:\n        return empty_string()\n    \n    return __wandb_key\n","metadata":{"execution":{"iopub.status.busy":"2023-06-14T14:21:59.173263Z","iopub.execute_input":"2023-06-14T14:21:59.17392Z","iopub.status.idle":"2023-06-14T14:21:59.32713Z","shell.execute_reply.started":"2023-06-14T14:21:59.173888Z","shell.execute_reply":"2023-06-14T14:21:59.326162Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"configuration = generate_config()\n\ndef generate_config_for_a_dataset() -> dict:\n    return {\n        'labels': [],\n        'size': zero(),\n        'seed': generate_random_seed(),\n        'shuffle': True,\n        'crop': False\n    }\n\ndef generate_config_view() -> dict:\n    return {\n        'height': 512,\n        'width': 512,\n        'channels': 3\n    }\n\ndef generate_config_datasets() -> dict:\n    return {\n        'split_validation_at': 0.45,\n        'training': generate_config_for_a_dataset(),\n        'validation': generate_config_for_a_dataset()\n    }\n\ndef generate_config() -> dict:\n    return {\n        'batch_size': 12,\n        'epochs': 10,\n\n        'view': generate_config_view(),\n        'dataset': generate_config_datasets(),\n    }\n\ndef get_configuration() -> dict:\n    global configuration\n    return configuration\n\ndef get_configuration_by_key(\n    key: str\n):\n    return get_configuration()[key]\n\ndef get_configuration_in_view_by_key(\n    key: str\n):\n    return get_configuration_by_key('view')[key]\n\ndef get_configuration_in_dataset_by_key(\n    key: str\n):\n    return get_configuration_by_key('dataset')[key]\n\ndef get_configuration_in_training_set_by_key(\n    key: str\n):\n    return get_configuration_in_dataset_by_key('training')[key]\n\ndef get_configuration_in_validation_set_by_key(\n    key: str\n):\n    return get_configuration_in_dataset_by_key('validation')[key]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#\nuse_cache: bool = False\nlog_runs: bool = True\n\ncache_buffer_size: int = AUTOTUNE\n\nepochs: int = \\\n    get_configuration_by_key('epochs')\n\ndataset_batch_size: int = \\\n    get_configuration_by_key('batch_size')\n\nvision_height: int = \\\n    get_configuration_in_view_by_key('height')\n\nvision_width: int = \\\n    get_configuration_in_view_by_key('width')\n\nvision_number_of_color_channels: int = \\\n    get_configuration_in_view_by_key('channels')\n\n\nvision_size = (\n    vision_height, \n    vision_width\n)\n\nvision_size_w_channels = (\n    vision_height, \n    vision_width, \n    vision_number_of_color_channels\n)\n\nsplit_dataset_at: float = \\\n    get_configuration_in_dataset_by_key('split_validation_at')\n\npath_to_model: str = '/kaggle/working/model'\npath_to_dataset: str = '/kaggle/input/letter-images-dataset/dataset'\n\ntraining_dataset = None\nvalidation_dataset = None\n\npointer_to_training_dataset = None\npointer_to_validation_dataset = None\n\nhistory = None\nmodel = None\n\n# Callbacks\nwandb_callback = None\n\nfit_callbacks = []\n\n# result\nresults: list = []\n\nstrategy = tensorflow.distribute.MirroredStrategy(\n    devices=get_gpus_to_use()\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def size_of_fit_callbacks() -> int:\n    global fit_callbacks\n    return len(fit_callbacks)\n\ndef fit_callbacks_is_empty() -> bool:\n    return size_of_fit_callbacks() == zero()\n\ndef fit_callbacks_has_content() -> bool:\n    return size_of_fit_callbacks() > zero()\n\ndef setup_callbacks() -> None:\n    global fit_callbacks\n    pass","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def start_process() -> None:\n    if get_log_runs():\n        wandb.login(\n            key=get_wandb_secret()\n        )\n        \ndef initialise_process() -> None:\n    if get_log_runs():\n        wandb.init(\n            project = 'letter-identification',\n            entity = 'designermadsen',    \n            config = configuration,\n            sync_tensorboard = True,\n            save_code = True,\n            monitor_gym = True\n        )\n\ndef end_process() -> None:\n    if get_log_runs():\n        wandb.finish()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_process()\n\ntraining_dataset = image_dataset_from_directory(\n    path_to_dataset,\n    validation_split = split_dataset_at,\n    subset= label_training(),\n    seed = get_configuration_in_training_set_by_key('seed'),\n    image_size = vision_size,\n    batch_size = dataset_batch_size,\n    shuffle = True,\n    crop_to_aspect_ratio = True\n)\n\nset_labels_of_training_set(\n    training_dataset.class_names\n)\n\nvalidation_dataset = image_dataset_from_directory(\n    path_to_dataset,\n    validation_split = split_dataset_at,\n    subset = label_validation(),\n    seed = get_configuration_in_validation_set_by_key('seed'),\n    image_size = vision_size,\n    batch_size = dataset_batch_size,\n    shuffle = True,\n    crop_to_aspect_ratio = True\n)\n\nset_labels_of_validation_set(\n    validation_dataset.class_names\n)\n\ninitialise_process()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_input_layers(\n    ml_layers: list\n) -> list:\n    global vision_size_w_channels\n    \n    ml_layers.append(\n        layers.Rescaling(\n            1./255, \n            input_shape=vision_size_w_channels, \n            trainable=True\n        )\n    )\n    \n    return ml_layers\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_middle_layers(\n    ml_layers: list\n) -> list:\n    merge_layer = (2, 2)\n    \n    ml_layers.append(\n        layers.Conv2D(\n            256, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            256, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.MaxPooling2D(\n            pool_size=merge_layer\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            128, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.MaxPooling2D(\n            pool_size=merge_layer\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            64, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            64, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            64, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            64, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.MaxPooling2D(\n            pool_size=merge_layer\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            64, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            64, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            64, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            64, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.MaxPooling2D(\n            pool_size=merge_layer\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            32, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            32, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            32, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            32, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.MaxPooling2D(\n            pool_size=merge_layer\n        )\n    )\n    \n    \n    ml_layers.append(\n        layers.Conv2D(\n            16, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            16, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            16, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.Conv2D(\n            16, \n            3, \n            padding='same', \n            activation='relu'\n        )\n    )\n    \n    ml_layers.append(\n        layers.MaxPooling2D(\n            pool_size=merge_layer\n        )\n    )\n    \n    return ml_layers","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_output_layers(\n    ml_layers: list\n) -> list:\n    \n    ml_layers.append(\n        layers.Flatten()\n    )\n    \n    decision_neurons_size = get_size_of_training_set_categories() * 8\n    \n    ml_layers.append(\n        layers.Dense(\n            decision_neurons_size, \n            activation='relu',\n        ),\n    )\n    \n    ml_layers.append(\n        layers.Dense(\n            get_size_of_training_set_categories()\n        )\n    )\n    \n    return ml_layers","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_layers() -> list:\n    layers = []\n    \n    layers = generate_input_layers(layers)\n    layers = generate_middle_layers(layers)\n    layers = generate_output_layers(layers)\n    \n    return layers\n\ndef make_model():\n    global vision_size_w_channels\n    \n    division = (2, 2)\n    \n    return \\\n        Sequential(\n            generate_layers()\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not (strategy is None):\n    with strategy.scope():\n        model = make_model()\nelse:\n    model = make_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam', \n    loss=SparseCategoricalCrossentropy(\n        from_logits=True\n    ),\n    metrics=['accuracy'], \n)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_cache:\n    pointer_to_training_dataset = training_dataset.cache().prefetch(\n        buffer_size=cache_buffer_size\n    )\n    \n    pointer_to_validation_dataset = validation_dataset.cache().prefetch(\n        buffer_size=cache_buffer_size\n    )\nelse:\n    pointer_to_training_dataset = training_dataset\n    pointer_to_validation_dataset = validation_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if get_log_runs():\n    wandb_callback = WandbCallback(\n        log_weights=True, \n        log_gradients=True, \n        training_data=pointer_to_training_dataset, \n        validation_data=pointer_to_validation_dataset,\n\n        log_evaluation=True, \n\n        monitor='val_accuracy',\n        mode='max'\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if fit_callbacks_is_empty():\n    setup_callbacks()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if fit_callbacks_has_content():\n    history = model.fit(\n        pointer_to_training_dataset,\n        validation_data = pointer_to_validation_dataset,\n        epochs=epochs,\n        callbacks=fit_callbacks\n    )\nelse:\n    history = model.fit(\n        pointer_to_training_dataset,\n        validation_data = pointer_to_validation_dataset,\n        epochs=epochs\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = {\n    'validation': {\n        'accuracy': history.history['val_accuracy'],\n        'loss': history.history['val_loss']\n    },\n    'result': {\n        'accuracy': history.history['accuracy'],\n        'loss': history.history['loss']\n    }\n}\n\nresults.append(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if get_log_runs():\n    wandb.log( \n        { \n        'training': results \n        } \n    )\n\nmodel.save(\n    path_to_model\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"end_process()","metadata":{},"execution_count":null,"outputs":[]}]}